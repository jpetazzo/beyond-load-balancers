---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: ollama
  name: ollama
spec:
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      volumes:
      - name: ollama
        hostPath:
          path: /opt/ollama
          type: DirectoryOrCreate
      - name: haproxy
        configMap:
          name: haproxy
      containers:
      - image: ollama/ollama
        name: ollama
        env:
        - name: OLLAMA_MAX_QUEUE
          valueFrom:
            configMapKeyRef:
              name: ollama
              key: queue
        - name: MODEL
          valueFrom:
            configMapKeyRef:
              name: ollama
              key: model
        volumeMounts:
        - name: ollama
          mountPath: /root/.ollama
        lifecycle:
          postStart:
            exec:
              command:
                - /bin/sh
                - -c
                - ollama pull $MODEL
        livenessProbe:
          httpGet:
            port: 11434
        readinessProbe:
          exec:
            command:
              - /bin/sh
              - -c
              - ollama show $MODEL
        ports:
        - name: ollama
          containerPort: 11434
        # These are commented out for learning purposes
        # (so that using this Deployment manifest as-is
        # results in resource contention).
        #resources:
        #  requests:
        #    cpu: 1
        #  limits: 
        #    cpu: 2
      - image: haproxy:3.0
        name: haproxy
        volumeMounts:
        - name: haproxy
          mountPath: /usr/local/etc/haproxy
        readinessProbe:
          httpGet:
            port: 9000
        ports:
        - name: haproxy
          containerPort: 8000
        - name: metrics
          containerPort: 9000
        resources:
          requests:
            cpu: 0.05
          limits:
            cpu: 1
